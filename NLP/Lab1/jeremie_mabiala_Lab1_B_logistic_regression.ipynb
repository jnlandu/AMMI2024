{"cells":[{"cell_type":"markdown","metadata":{"id":"dGmTzE_rvoPE"},"source":["# MMI_2024_NLP - Week 1\n","\n","#Lab 1: Part 2\n","\n","\n","### Jeremie Mabiala\n","\n"]},{"cell_type":"markdown","metadata":{"id":"V1i2nROpqNn8"},"source":["# Introduction\n","\n","Before we start, please change the name of the notebook to the following format : **Firstname_LASTNAME_Lab1_B_logistic_regression.ipynb**\n","\n","\n","In some cells and files you will see code blocks that look like this:\n","\n","```python\n","##############################################################################\n","#                    TODO: Write the equation for a line                     #\n","##############################################################################\n","pass\n","##############################################################################\n","#                              END OF YOUR CODE                              #\n","##############################################################################\n","```\n","\n","You should replace the `pass` statement with your own code and leave the blocks intact, like this:\n","\n","```python\n","##############################################################################\n","#                    TODO: Write the equation for a line                     #\n","##############################################################################\n","y = m * x + b\n","##############################################################################\n","#                              END OF YOUR CODE                              #\n","##############################################################################\n","```"]},{"cell_type":"markdown","metadata":{"id":"E6295bUoqSbf"},"source":["# (B) Logistic Regression Model"]},{"cell_type":"markdown","metadata":{"id":"p5uCE1MSm7br"},"source":["In this second part of the lab, we will implement a language identifier trained on the same data, but using Logistic Regression instead of Naive Bayes."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"tnQyS9w9m7bu"},"outputs":[],"source":["import io, sys, math\n","import numpy as np\n","from collections import defaultdict\n","from tqdm.notebook import tqdm,trange\n","from typing import Tuple, List, Dict\n","import random"]},{"cell_type":"markdown","metadata":{"id":"SqHxJJa7m7bv"},"source":["This function is used to build the dictionary, or vocabulary, which is a mapping from strings (or words) to integers (or indices). This will allow to build vector representations of documents."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-vXdFjspm7bv"},"outputs":[],"source":["def build_dict(filename:str, threshold:int=1)->Tuple[Dict]:\n","    \"\"\"\n","    Input:\n","    - filename: the name of the data file.\n","    - threshold: is the minimum number of times the word has to appear in the data to be added to the vocabulary.\n","    Output:\n","    - word_dict: the vocabulary generated from the dataset.\n","    - label_dict: the dictionary of the labels, with labels as keys and their indices as values of these keys.\n","    \"\"\"\n","    fin = io.open(filename, 'r', encoding='utf-8')\n","    word_dict, label_dict = {}, {}\n","    counts = defaultdict(lambda: 0)\n","    for line in tqdm(fin):\n","        tokens = line.split()\n","        label = tokens[0]\n","\n","        if not label in label_dict:\n","            label_dict[label] = len(label_dict)\n","\n","        for w in tokens[1:]:\n","            counts[w] += 1\n","\n","    for k, v in counts.items():\n","        if v > threshold:\n","            word_dict[k] = len(word_dict)\n","    return word_dict, label_dict"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2acf13908fb484198801e4db7af5d24","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["word_dict, label_dict = build_dict('train1.txt')"]},{"cell_type":"markdown","metadata":{"id":"5nIdAGsum7bw"},"source":["This function is used to load the training dataset, and build vector representations of the training examples. In particular, a document or sentence is represented as a bag of words. Each example correspond to a sparse vector ` x` of dimension `V`, where `V` is the size of the vocabulary. The element `j` of the vector `x` is the number of times the word `j` appears in the document."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"HgcK2pRrm7bw"},"outputs":[],"source":["def load_data(filename:str, word_dict:Dict, label_dict:Dict)->List[Tuple]:\n","    fin = io.open(filename, 'r', encoding='utf-8')\n","    data = []\n","    dim = len(word_dict) #The size of the vocabulary.\n","    for line in tqdm(fin):\n","        tokens = line.split() #Consider tokenization by space in this case.\n","        label = tokens[0]\n","\n","        yi = label_dict[label]\n","        xi = np.zeros(dim)\n","        for word in tokens[1:]:\n","            if word in word_dict:\n","                wid = word_dict[word]\n","                xi[wid] += 1.0\n","        data.append((yi, xi))\n","    return data"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f98635c9e5a4ae29ada6cdeb6d542b9","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[(0, array([1., 1., 1., ..., 0., 0., 0.])),\n"," (0, array([0., 0., 0., ..., 0., 0., 0.])),\n"," (1, array([0., 0., 0., ..., 0., 0., 0.])),\n"," (0, array([0., 0., 0., ..., 0., 0., 0.])),\n"," (2, array([0., 0., 0., ..., 0., 0., 0.]))]"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["d = load_data('train1.txt', word_dict=word_dict, label_dict=label_dict)\n","d[:5]"]},{"cell_type":"markdown","metadata":{"id":"DgKPoEmQm7bx"},"source":["First, let's implement the softmax function. Don't forget numerical stability!"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"XXZcrv0im7bx"},"outputs":[],"source":["def softmax(x:np.ndarray)->np.ndarray:\n","  ##########################################################################\n","  #                      TODO: Implement this function                     #\n","  ##########################################################################\n","  # Replace \"pass\" statement with your code\n","  z = np.sum(np.exp(x-max(x)))\n","\n","  return np.exp(x-max(x))/z\n","  ##########################################################################\n","  #                            END OF YOUR CODE                            #\n","  ##########################################################################"]},{"cell_type":"markdown","metadata":{"id":"_1YF7GrOm7bx"},"source":["Now, let's implement the main training loop, by using stochastic gradient descent. The function will iterate over the examples of the training set. For each example, we will first compute the loss, before computing the gradient and performing the update."]},{"cell_type":"code","execution_count":43,"metadata":{"id":"MZ8dsdb8m7bx"},"outputs":[],"source":["def sgd(w:np.ndarray, data:List[Tuple], niter:int, lr:float = 0.001)->np.ndarray:\n","    \"\"\"\n","    Input:\n","    - w: the weight matrix of shape (length of label dictionary, length of word dictionary)\n","    - data: the dataset.\n","    - niter: number of epochs, or number of passes on the all dataset.\n","    - lr: the learning rate.\n","\n","    Output:\n","    - w: the weight matrix.\n","    \"\"\"\n","    random.seed(123)\n","    nlabels, dim = w.shape\n","    loss_lis = []\n","\n","    for iter in trange(niter):\n","      ##########################################################################\n","      #                      TODO: Implement this function                     #\n","      ##########################################################################\n","      # Replace \"pass\" statement with your code\n","\n","      for label, x in data:\n","         one_hot_label = np.eye(nlabels)[label] #true_labels \n","\n","         s= np.dot(w,x)\n","\n","         ## Softmax out\n","         out = softmax(s) \n","\n","         ## Gradient at w\n","         dlw = (out-one_hot_label).reshape(-1,1)*x.reshape(-1,1).T\n","\n","         ## Update rule:\n","         w = w - lr* dlw\n","      ##########################################################################\n","      #                            END OF YOUR CODE                            #\n","      ##########################################################################\n","\n","    return w # Replace \"...\" statement with your code"]},{"cell_type":"markdown","metadata":{"id":"RfrLiyCTm7by"},"source":["The next function will predict the most probable label corresponding to example `x`, given the trained classifier `w`."]},{"cell_type":"code","execution_count":44,"metadata":{"id":"uMHNaYB4m7by"},"outputs":[],"source":["def predict(w:np.ndarray, x:np.ndarray)->np.ndarray:\n","  ##########################################################################\n","  #                      TODO: Implement this function                     #\n","  ##########################################################################\n","  # Replace \"pass\" statement with your code\n","  return np.argmax(np.dot(w,x))\n","  ##########################################################################\n","  #                            END OF YOUR CODE                            #\n","  ##########################################################################"]},{"cell_type":"markdown","metadata":{"id":"R897_5jJm7by"},"source":["Finally, this function will compute the accuracy of a trained classifier `w` on a validation set."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"2I9tYxCBm7by"},"outputs":[],"source":["def compute_accuracy(w:np.ndarray, valid_data:List[Tuple])->float:\n","  ##########################################################################\n","  #                      TODO: Implement this function                     #\n","  ##########################################################################\n","  # Replace \"pass\" statement with your code\n","  acc = 0.0\n","  for label, x in valid_data:\n","    new_label = predict(w,x)\n","    if new_label == label:\n","      acc +=1\n","  return acc/len(valid_data)\n","  ##########################################################################\n","  #                            END OF YOUR CODE                            #\n","  ##########################################################################\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","** Logistic Regression **\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e326ee92b20b4605a169dc1997387424","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e4a2106348b4e91a8564069a1370518","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc96f111394943bda3834adbd28727c2","version_major":2,"version_minor":0},"text/plain":["0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"736726f6a6f64662ab55d790317a6c4b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/25 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Validation accuracy: 0.882\n","\n"]}],"source":["print(\"\")\n","print(\"** Logistic Regression **\")\n","print(\"\")\n","\n","word_dict, label_dict = build_dict(\"train1.txt\")\n","train_data = load_data(\"train1.txt\", word_dict, label_dict)\n","valid_data = load_data(\"valid1.txt\", word_dict, label_dict)\n","\n","nlabels = len(label_dict)\n","\n","dim = len(word_dict)\n","w = np.zeros([nlabels, dim])\n","w = sgd(w, train_data, 25)\n","print(\"\")\n","print(\"Validation accuracy: %.3f\" % compute_accuracy(w, valid_data))\n","print(\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SAqRAq38NTVC"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"DAaC78iUPf13"},"source":["# Recommended Reading:\n","\n","- https://people.tamu.edu/~sji/classes/LR.pdf\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"155b2299d2c2402b88e30eec737c1456":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1b15e60cde8e4ac688689a7aa1e43426":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"245f40680d4449cca9c27195531dd9f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6ffc075c3f6461fae9746437d6064c9","placeholder":"​","style":"IPY_MODEL_43fd682975804e62beecc55c8b1ac9a0","value":"Epoch 1/5 Loss 11.934367527601534:   3%"}},"34db7fbe2bff45a3a75808e8810aafd9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43fd682975804e62beecc55c8b1ac9a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5cc69669e6af483e982d4907f67a1c6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d04ccbe01b54a24b2e54f71534ddd99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b15e60cde8e4ac688689a7aa1e43426","placeholder":"​","style":"IPY_MODEL_155b2299d2c2402b88e30eec737c1456","value":" 305/10000 [00:02&lt;01:02, 154.50it/s]"}},"8160219b08744de0ac98939651e0ffc4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_245f40680d4449cca9c27195531dd9f7","IPY_MODEL_8455add820404f5c956d69b555db5220","IPY_MODEL_5d04ccbe01b54a24b2e54f71534ddd99"],"layout":"IPY_MODEL_5cc69669e6af483e982d4907f67a1c6a"}},"8455add820404f5c956d69b555db5220":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_34db7fbe2bff45a3a75808e8810aafd9","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec52a54607514da7843fd506fe889a9d","value":306}},"e6ffc075c3f6461fae9746437d6064c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec52a54607514da7843fd506fe889a9d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
