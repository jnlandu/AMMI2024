{"cells":[{"cell_type":"markdown","metadata":{"id":"thobkiOZ76P9"},"source":["\n","<h1 style=\"font-family:verdana;font-size:300%;text-align:center;background-color:#f2f2f2;color:#0d0d0d\">AMMI_2024_NLP - Week 1</h1>\n","\n","<h1 style=\"font-family:verdana;font-size:180%;text-align:Center;color:#993333\"> Lab 3: N-gram models </h1>\n","\n","\n","Before we start, please change the name of the notebook to the following format : **Firstname_LASTNAME_Lab3__N_gram_models.ipynb**\n","\n","\n","In some cells and files you will see code blocks that look like this:\n","\n","```python\n","##############################################################################\n","#                    TODO: Write the equation for a line                     #\n","##############################################################################\n","pass\n","##############################################################################\n","#                              END OF YOUR CODE                              #\n","##############################################################################\n","```\n","\n","You should replace the `pass` statement with your own code and leave the blocks intact, like this:\n","\n","```python\n","##############################################################################\n","#                    TODO: Write the equation for a line                     #\n","##############################################################################\n","y = m * x + b\n","##############################################################################\n","#                              END OF YOUR CODE                              #\n","##############################################################################\n","```"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"AO2Q6hrQ76QC"},"outputs":[],"source":["import io, sys, math, re\n","from collections import defaultdict\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NywuM_YBXKOq","outputId":"d6c6d604-73b2-4e13-ee66-6720329d4138"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount(\"drive\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"wG9pqSoV76QD"},"outputs":[],"source":["# data_loader\n","def load_data(filename):\n","    '''\n","    parameters:\n","    filename (string): datafile\n","\n","    Returns:\n","    data (list of lists): each list is a sentence of the text\n","    vocab (dictionary): {word: no of times it appears in the text}\n","    '''\n","    fin = io.open(filename, 'r', encoding='utf-8')\n","    data = []\n","    vocab = defaultdict(lambda:0)\n","    for line in fin:\n","        sentence = line.split()\n","        data.append(sentence)\n","        for word in sentence:\n","            vocab[word] += 1\n","    return data, vocab"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"amQ02wsD76QE","outputId":"fb7e6f00-fad7-4240-f6ec-4c247519389f"},"outputs":[{"name":"stdout","output_type":"stream","text":["load training set..\n","\n","\n","['<s>', 'my', 'fathers', \"don't\", 'speak', 'dutch.', '</s>']\n","\n","\n","how : 107\n","load validation set\n"]}],"source":["\n","data_pth = \"/Users/jeremie/Documents/AMMI-2024/AMMI2024/NLP/Lab3/\"\n","print(\"load training set..\")\n","print(\"\\n\")\n","train_data, vocab = load_data(data_pth+\"train1.txt\")\n","print(train_data[0])\n","print(\"\\n\")\n","print(\"how :\",vocab['how'])\n","print(\"load validation set\")\n","valid_data, _ = load_data(data_pth + \"valid1.txt\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"6kfh1SAS76QE"},"outputs":[],"source":["def remove_rare_words(data, vocab, mincount = 1):\n","    '''\n","    Parameters:\n","    data (list of lists): each list is a sentence of the text\n","    vocab (dictionary): {word: no of times it appears in the text}\n","    mincount(int): the minimum count\n","\n","    Returns:\n","    data_with_unk(list of lists): data after replacing rare words with <unk> token\n","    '''\n","    # replace words in data that are not in the vocab\n","    # or have a count that is below mincount\n","    data_with_unk = []\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","    for sent in range(len(data)):\n","        for word_index in range(len(data[sent])):\n","            if vocab[data[sent][word_index]] < mincount:\n","                data[sent][word_index] = '<unk>'\n","    # replace words in data that are not in the vocab \n","    # or have a count that is below mincount\n","    return data\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["remove rare words\n","['<s>', 'my', '<unk>', \"don't\", 'speak', '<unk>', '</s>']\n"]}],"source":["print(\"remove rare words\")\n","\n","train_data = remove_rare_words(train_data, vocab, mincount = 2)\n","valid_data = remove_rare_words(valid_data, vocab, mincount = 1)\n","#train_data\n","print(train_data[0])"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iEB_VcVj76QF","outputId":"48943fb9-d0d3-4593-887d-e1235fbc9768"},"outputs":[{"name":"stdout","output_type":"stream","text":["remove rare words\n","['<s>', 'my', '<unk>', \"don't\", 'speak', '<unk>', '</s>']\n"]}],"source":["print(\"remove rare words\")\n","\n","train_data = remove_rare_words(train_data, vocab, mincount = 2)\n","valid_data = remove_rare_words(valid_data, vocab, mincount = 1)\n","#train_data\n","print(train_data[0])"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"pNXHA3zS76QF"},"outputs":[],"source":["def build_ngram(data, n):\n","    '''\n","    Parameters:\n","    data (list of lists): each list is a sentence of the text\n","    n (int): size of the n-gram\n","\n","    Returns:\n","    prob (dictionary of dictionary)\n","    {\n","        context: {word:probability of this word given context}\n","    }\n","    '''\n","    total_number_words = 0\n","    counts = defaultdict(lambda: defaultdict(lambda: 0.0))\n","    counts_n1 = defaultdict(lambda: 0.0)\n","    for sentence in data:\n","        sentence = tuple(sentence)\n","        ##########################################################################\n","        #                      TODO: Implement this function                     #\n","        # dict can be indexed by tuples\n","        # store in the same dict all the ngrams\n","        # by using the context as a key and the word as a value\n","        ##########################################################################\n","        # Replace \"pass\" statement with your code\n","        for w in range(len(sentence)-1):\n","            wt = sentence[w:w+n][-1]\n","            new_n = n-1\n","            counts_n1[wt] += 1.0\n","            while new_n >= 0:\n","                if new_n == 0:\n","                    wt_n = '<empty>'\n","                else:\n","                    wt_n = ' '.join(sentence[w:w+new_n])\n","                counts[wt_n][wt] += 1.0\n","                counts_n1[wt_n] += 1.0\n","                total_number_words += 1.0\n","                new_n -= 1\n","        ##########################################################################\n","        #                            END OF YOUR CODE                            #\n","        ##########################################################################\n","\n","    prob = defaultdict(lambda: defaultdict(lambda: 0.0))\n","    # Build the probabilities from the counts\n","    # Be careful with how you normalize!\n","\n","    # for context in counts.keys():\n","      # p(w | context) = count(context, w)/ count(context)\n","      ##########################################################################\n","      #                      TODO: Implement this function                     #\n","      ##########################################################################\n","      # Replace \"pass\" statement with your code\n","    for wt_n in counts:\n","      for wt in counts[wt_n]:\n","          if wt_n == '<empty>':\n","              prob[wt_n][wt] = (counts_n1[wt]+1) / (counts_n1[wt]+1)\n","          else:\n","              prob[wt_n][wt] = (counts[wt_n][wt]+1) / (total_number_words+counts_n1[wt_n])\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################\n","\n","    return prob"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["build ngram model with n =  10\n"]}],"source":["# RUN TO BUILD NGRAM MODEL\n","n = 10\n","print(\"build ngram model with n = \", n)\n","model = build_ngram(train_data, n)\n"]},{"cell_type":"markdown","metadata":{"id":"KbCzRXJk76QG"},"source":["Here, implement a recursive function over shorter and shorter context to compute a \"stupid backoff model\". An interpolation model can also be implemented this way."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"AbOs6Duc76QG"},"outputs":[],"source":["def get_prob(model, context, w):\n","    '''\n","    Parameters:\n","    model (dictionary of dictionary)\n","    {\n","        context: {word:probability of this word given context}\n","    }\n","    context (list of strings): a sentence\n","    w(string): the word we need to find it's probability given the context\n","\n","    Retunrs:\n","    prob(float): probability of this word given the context\n","    '''\n","\n","    # code a recursive function over\n","    # smaller and smaller context\n","    # to compute the backoff model\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","    prob = 0.0\n","    new_context = context.split(' ')\n","    for i in range(len(new_context)):\n","        prob = model[' '.join(new_context[i:])][w]\n","        if prob != 0:\n","            return prob\n","    return model['<empty>'][w]*0.4\n","        \n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"z5waVP3C76QH"},"outputs":[],"source":["def perplexity(model, data, n):\n","    '''\n","    Parameters:\n","    model (dictionary of dictionary)\n","    {\n","        context: {word:probability of this word given context}\n","    }\n","    data (list of lists): each list is a sentence of the text\n","    n(int): size of the n-gram\n","\n","    Retunrs:\n","    perp(float): the perplexity of the model\n","    '''\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","    perp = 0.0\n","    all_words = 0.0\n","    for sentence in data:\n","        for w in range(len(sentence)-1):\n","            w,context = sentence[w:w+n][-1],' '.join(sentence[w:w+n][:-1])\n","            prob = get_prob(model, context, w)\n","            perp += np.log(prob)\n","            all_words += 1.0\n","\n","    return np.exp(-perp/all_words)\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AYBc5Aam76QH","outputId":"ee54fd0a-fe39-4e25-b479-a2d62274a623"},"outputs":[{"name":"stdout","output_type":"stream","text":["The perplexity is inf\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/c0/yycmqs6n025cf5d24rf0j6pr0000gp/T/ipykernel_25414/3773272274.py:24: RuntimeWarning: divide by zero encountered in log\n","  perp += np.log(prob)\n"]}],"source":["# COMPUTE PERPLEXITY ON VALIDATION SET\n","\n","print(\"The perplexity is\", perplexity(model, valid_data, n=n))"]},{"cell_type":"code","execution_count":78,"metadata":{"id":"idrxoRlc76QH"},"outputs":[],"source":["def get_proba_distrib(model, context):\n","    ## need to get the the words after the context and their probability of appearance\n","    ## after this context\n","    '''\n","    Parameters:\n","    model (dictionary of dictionary)\n","    {\n","        context: {word:probability of this word given context}\n","    }\n","    context (list of strings): the sentence we need to find the words after it and\n","    thier probabilites\n","\n","    Retunrs:\n","    words_and_probs(dic): {word: probability of word given context}\n","\n","    '''\n","    # code a recursive function over context\n","    # to find the longest available ngram\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","    if sum(model[context].values()) != 0:\n","        return context\n","    else:\n","        context = ' '.join(context.split(' ')[:-1])\n","        return get_proba_distrib(model,context)\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"probabilities do not sum to 1","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[79], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m     p_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(model[letter]\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      7\u001b[0m     p_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(model[letter]\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m---> 11\u001b[0m     word \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp_proba\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     13\u001b[0m     sentence1\u001b[38;5;241m.\u001b[39mappend(word)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(sentence1)\n","File \u001b[0;32mnumpy/random/mtrand.pyx:975\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: probabilities do not sum to 1"]}],"source":["sentence = [\"<s>\", 'je', 'suis', 'tu', 'elle', 'ma']\n","sentence1 = ['<s>']\n","\n","while sentence1 != '<s>':\n","    letter = get_proba_distrib(model, ' '.join(sentence1))\n","    p_words = list(model[letter].keys())\n","    p_proba = list(model[letter].values())\n","\n","\n","\n","    word = np.random.choice(p_words, 1, p=p_proba)[0]\n","\n","    sentence1.append(word)\n","print(sentence1)\n","\n","\n"]},{"cell_type":"code","execution_count":59,"metadata":{"id":"i_eGYoZB76QI"},"outputs":[],"source":["def generate(model):\n","    '''\n","    Parameters:\n","    model (dictionary of dictionary)\n","    {\n","        context: {word:probability of this word given context}\n","    }\n","\n","    Retunrs:\n","    sentence (list of strings): a sentence sampled according to the language model.\n","\n","\n","    '''\n","    # # generate a sentence. A sentence starts with a <s> and ends with a </s>\n","    # # Possiblly a use function is:\n","    # # np.random.choice(x, 1, p = y)\n","\n","    # # where x is a list of things to sample from\n","    # # and y is a list of probability (of the same length as x)\n","    # sentence = [\"<s>\"]\n","    # n =10\n","    # #print (model[(\"<s>\")])\n","    # #print (len(model[tuple(sentence)].values()))\n","    # max_len =25\n","    # while sentence[-1] != \"</s>\" and len(sentence)<10:\n","    #     ##########################################################################\n","    #     #                      TODO: Implement this function                     #\n","    #     ##########################################################################\n","    #     # Replace \"pass\" statement with your code\n","    #     letter = get_proba_distrib(model,' '.join(sentence))\n","    #     possible_words = list(model[letter].keys())\n","    #     possible_prob = list(model[letter].values())\n","\n","    #     # # possible_prob\n","    #     word = np.random.choice(possible_words, 1,p=possible_prob)[0]\n","    #     sentence.append(word)\n","    #     n+=1\n","    #     if n > max_len:\n","    #         break\n","    # return sentence\n","        ##########################################################################\n","        #                            END OF YOUR CODE                            #\n","        ##########################################################################\n","\n","    \n","    sentence = [\"<s>\"]\n","        \n","    MAX_LEN = 50\n","    n = 0\n","    while sentence[-1] != '</s>':\n","        letter = get_proba_distrib(model,' '.join(sentence))\n","        possible_words = list(model[letter].keys())\n","        possible_prob = list(model[letter].values())\n","\n","        # # possible_prob\n","        word = np.random.choice(possible_words, 1,p=None)[0]\n","        sentence.append(word)\n","        n+=1\n","        if n > MAX_LEN:\n","            break\n","    # generate a sentence. A sentence starts with a <s> and ends with a </s>\n","    # Possiblly a use function is:\n","    #   np.random.choice(x, 1, p = y)\n","    # where x is a list of things to sample from\n","    # and y is a list of probability (of the same length as x)\n","    print(sum(possible_prob))\n","    print(list(model[letter].values())[:3])\n","    return sentence"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.010491603273747386\n","[0.004602990057738255, 2.295755639769703e-05, 0.0003738802041910659]\n","Generated sentence:  ['<s>']\n"]}],"source":["print(\"Generated sentence: \",generate(model))"]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mWqzUXjw76QI","outputId":"ef1984bc-acf7-4f85-9c40-1e0d9c214839"},"outputs":[{"name":"stdout","output_type":"stream","text":["3.309828037884292e-06\n","[3.309828037884292e-06]\n","Generated sentence:  ['<s>', 'pass', '</s>']\n"]}],"source":["# GENERATE A SENTENCE FROM THE MODEL\n","\n","print(\"Generated sentence: \",generate(model))"]},{"cell_type":"markdown","metadata":{"id":"XCs2pG6P76QJ"},"source":["Once you are done implementing the model, evaluation and generation code, you can try changing the value of `n`, and play with a larger training set (`train2.txt` and `valid2.txt`). You can also try to implement an interpolation model."]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["load training set 2..\n","\n","\n","['<s>', 'i', 'liked', 'your', 'idea', 'and', 'adopted', 'it', '.', '</s>']\n","\n","\n","how : 3195\n","load validation set 2\n"]}],"source":["print(\"load training set 2..\")\n","print(\"\\n\")\n","train_data2, vocab = load_data(data_pth + \"train2.txt\")\n","print(train_data2[0])\n","print(\"\\n\")\n","print(\"how :\",vocab['how'])\n","print(\"load validation set 2\")\n","valid_data2, _ = load_data(data_pth + \"valid2.txt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"INh4pNmm76QJ","outputId":"19fe5739-20dc-4285-a227-76f8212020b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["load training set 2..\n","\n","\n","['<s>', 'i', 'liked', 'your', 'idea', 'and', 'adopted', 'it', '.', '</s>']\n","\n","\n","how : 3195\n","load validation set 2\n"]}],"source":["print(\"load training set 2..\")\n","print(\"\\n\")\n","train_data2, vocab = load_data(\"drive/MyDrive/nlp_week1_lab3_train2.txt\")\n","print(train_data2[0])\n","print(\"\\n\")\n","print(\"how :\",vocab['how'])\n","print(\"load validation set 2\")\n","valid_data2, _ = load_data(\"drive/MyDrive/nlp_week1_lab3_valid2.txt\")\n"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"xyEO8rKZB6SR"},"outputs":[],"source":["n = 3"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"tq71nPJjBZRR"},"outputs":[],"source":["model = build_ngram(train_data2, n)"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"data":{"text/plain":["39953.97617821502"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["perplexity(model,valid_data2, n)"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nHcKA9nxBpXk","outputId":"ebd44ab9-f17a-406e-affb-0db0df5766d7"},"outputs":[{"data":{"text/plain":["39953.97617821502"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["perplexity(model,valid_data2, n)"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.031168655573115784\n","[5.93020621699099e-06, 0.0004915293781568818, 2.5245735038047355e-05]\n"]},{"data":{"text/plain":["['<s>',\n"," 'disappeared',\n"," 'grandpa',\n"," 'rings',\n"," 'sand',\n"," 'nature',\n"," 'five',\n"," 'lemon',\n"," 'may',\n"," 'silent',\n"," 'exports',\n"," 'everywhere',\n"," 'jet',\n"," 'bathroom',\n"," 'give',\n"," 'approach',\n"," 'tend',\n"," 'movie',\n"," 'surely',\n"," 'spends',\n"," 'drank',\n"," 'pages',\n"," 'audience',\n"," 'budget',\n"," 'angeles',\n"," 'were',\n"," 'host',\n"," 'sold',\n"," 'approaching',\n"," 'move',\n"," 'statement',\n"," 'tradition',\n"," 'york',\n"," 'like',\n"," 'emerged',\n"," 'closely',\n"," 'repair',\n"," 'race',\n"," 'signed',\n"," 'council',\n"," 'crossing',\n"," 'follow',\n"," 'taxes',\n"," 'author',\n"," 'writer',\n"," 'drama',\n"," 'all',\n"," 'added',\n"," 'downstairs',\n"," 'race',\n"," 'section',\n"," 'planes']"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["generate(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7vh3LzcBvHj","outputId":"6be8fd9f-711e-484b-b7ec-af11e6bb5769"},"outputs":[{"data":{"text/plain":["['<s>', 'is', 'a', 'yen', 'over', 'matter', 'much', '</s>']"]},"execution_count":331,"metadata":{},"output_type":"execute_result"}],"source":["generate(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4f-xb6wBB3tn"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
